{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSV_to_RDF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AO1-cVk8fXh"
      },
      "source": [
        "first we have to install the library [rdflib](https://rdflib.readthedocs.io/en/stable/) and import it next to [pandas](https://pandas.pydata.org/), which helbs to work with a csv file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVWy4-a28PzK",
        "outputId": "3ae3f155-42d2-4878-9ece-187dc7ef8e4f"
      },
      "source": [
        "!pip install rdflib\r\n",
        "from rdflib import Graph, Literal, Namespace, URIRef\r\n",
        "from rdflib.namespace import DCTERMS, RDF, RDFS, SKOS, XSD\r\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 6.6MB/s \n",
            "\u001b[?25hCollecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib) (2.4.7)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.0 rdflib-5.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVAOEUJe_yzP"
      },
      "source": [
        "`result_graph` contains the rdf graph we want to generate and serialize in a new output file. we predefine alle needed namespaces and add them to `result_graph`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPImu9_a7ORV"
      },
      "source": [
        "#\r\n",
        "result_graph = Graph()\r\n",
        "\r\n",
        "GAMS = Namespace(\"https://gams.uni-graz.at/o:gams-ontology#\") \r\n",
        "VOID = Namespace(\"http://rdfs.org/ns/void#\")\r\n",
        "FOAF = Namespace(\"http://xmlns.com/foaf/spec/\")\r\n",
        "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\r\n",
        "DC = Namespace(\"http://purl.org/dc/elements/1.1/\")\r\n",
        "OL = Namespace(\"http://olympia-ontology#\")\r\n",
        "\r\n",
        "result_graph.bind(\"gams\", GAMS)\r\n",
        "result_graph.bind(\"void\", VOID)\r\n",
        "result_graph.bind(\"foaf\", FOAF)\r\n",
        "result_graph.bind(\"dcterms\", DCTERMS)\r\n",
        "result_graph.bind(\"dc\", DC)\r\n",
        "result_graph.bind(\"ol\", OL)\r\n",
        "\r\n",
        "# so that https://gams.uni-graz.at/olympia.1 is the URL of our RDF document somewhere in the web\r\n",
        "BASE_URL = \"https://gams.uni-graz.at/\"\r\n",
        "DOCUMENT_ID = \"olympia.1\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w83GtGBAB-4o"
      },
      "source": [
        "loading the data into a new panda dataframe. upload the `athlete_events_smaller.csv` into the *data* folder. the csv contains 2500 athletes for each multiple rows can exist. the header of the CSV looks like the following;\r\n",
        "\r\n",
        "\"ID\",\"Name\",\"Sex\",\"Age\",\"Height\",\"Weight\",\"Team\",\"NOC\",\"Games\",\"Year\",\"Season\",\"City\",\"Sport\",\"Event\",\"Medal\"\r\n",
        "\r\n",
        "**YOU HAVE TO REUPLOAD THE CSV INPUT INTO THE CORRECT FOLDER \"content\" !!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "GioPsib5A8fA",
        "outputId": "125726b2-0e31-4159-f21d-cf11a5bb0d30"
      },
      "source": [
        "df = pd.read_csv(\"athlete_events_smaller.csv\", encoding=\"utf8\") \r\n",
        "print(df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-75d0eeacff88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"athlete_events_smaller.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'athlete_events_smaller.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M51vM_owDLOI"
      },
      "source": [
        "groups all rows by \"ID\" and add properties to ol:Athlete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL9ZbIunDGYX"
      },
      "source": [
        "#for group in df.groupby('ID'):\r\n",
        "#    print(group)\r\n",
        "\r\n",
        "groups_by_id = df.groupby('ID')\r\n",
        "#print(BASE_URL)\r\n",
        "\r\n",
        "for ID, group in groups_by_id:\r\n",
        "  # create <ol:Athlete rdf:about=\"https://gams.uni-graz.at/olympia.1#9792\"/>\r\n",
        "  athlete = URIRef(BASE_URL + DOCUMENT_ID + \"#\" + str(ID))\r\n",
        "  result_graph.add((athlete, RDF.type, OL.Athlete))\r\n",
        "  \r\n",
        "  # second loop for every group\r\n",
        "  for datafield in group:\r\n",
        "    if(datafield == \"Name\"):\r\n",
        "      result_graph.add(( athlete, FOAF.name, Literal(group[datafield].values[0]) ))\r\n",
        "    if(datafield == \"Height\"):\r\n",
        "      result_graph.add(( athlete, OL.height, Literal(group[datafield].values[0]) ))\r\n",
        "    if(datafield == \"Weight\"):\r\n",
        "      result_graph.add(( athlete, OL.weight, Literal(group[datafield].values[0]) ))\r\n",
        "    if(datafield == \"Age\"):\r\n",
        "      result_graph.add(( athlete, OL.age, Literal(group[datafield].values[0]) ))\r\n",
        "    if(datafield == \"Sex\"):\r\n",
        "      result_graph.add(( athlete, FOAF.gender, Literal(group[datafield].values[0]) ))\r\n",
        "    if(datafield == \"Team\"):\r\n",
        "      result_graph.add(( athlete, OL.team, Literal(group[datafield].values[0]) ))\r\n",
        "\r\n",
        "    #  \r\n",
        "    if(datafield == \"Season\"):\r\n",
        "      # ol:Result rdf:about=\"https://gams.uni-graz.at/olympia.1#144Result\" , ol:season, ol:year, ol:discipline\r\n",
        "      result = URIRef(BASE_URL + DOCUMENT_ID + \"#\" + str(ID) + \"Result\")\r\n",
        "      result_graph.add((result, RDF.type, OL.Result))\r\n",
        "      result_graph.add(( athlete, OL.result, result ))\r\n",
        "\r\n",
        "      result_graph.add(( result, OL.season, Literal(group[\"Season\"].values[0]) ))\r\n",
        "      result_graph.add(( result, OL.year, Literal(group[\"Year\"].values[0]) ))\r\n",
        "\r\n",
        "      # <ol:Discipline rdf:about=\"https://gams.uni-graz.at/olympia.1#144Discipline\">\r\n",
        "      discipline = URIRef(BASE_URL + DOCUMENT_ID + \"#\" + str(ID) + \"Discipline\")\r\n",
        "      result_graph.add(( result, OL.discipline, discipline ))\r\n",
        "      result_graph.add(( discipline, RDF.type, OL.Discipline ))\r\n",
        "\r\n",
        "      result_graph.add(( discipline, OL.sport,  Literal(group[\"Sport\"].values[0])  ))\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q2GJvtEHxD1"
      },
      "source": [
        "create new file\r\n",
        "* format=\"xml\" - creates plain xml/rdf\r\n",
        "* format=\"pretty-xml\" - abbreviated RDF/XML syntax \r\n",
        "+ format=\"turtle\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chGLcPc-Ht1N"
      },
      "source": [
        "result_graph.serialize(destination = 'output.xml', format=\"pretty-xml\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}